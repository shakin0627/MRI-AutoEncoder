{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a3012465-7f66-4e85-963e-2bde5acf590d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch version: 2.6.0+cpu\n",
      "torchvision version: 0.21.0+cpu\n"
     ]
    }
   ],
   "source": [
    "# ------ 1. 检查torchvision版本 ------\n",
    "import torch\n",
    "import torchvision\n",
    "\n",
    "print(\"torch version:\", torch.__version__)\n",
    "print(\"torchvision version:\", torchvision.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2dafe20f-04c8-4f58-b3f2-9d2fa88829cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ====== 2. 导入依赖 ======\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "import pytorch_lightning as pl\n",
    "\n",
    "from datasets import get_dataset\n",
    "from models.autoencoder import PreTrained_AutoEncoder\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ac28455b-0778-4971-a7ca-0c4deec827eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created train/Patient001: T1.png, T2.png\n",
      "Created train/Patient002: T1.png, T2.png\n",
      "Created train/Patient003: T1.png, T2.png\n",
      "Created train/Patient004: T1.png, T2.png\n",
      "Created val/Patient001: T1.png, T2.png\n",
      "Created val/Patient002: T1.png, T2.png\n",
      "Created val/Patient003: T1.png, T2.png\n",
      "Created val/Patient004: T1.png, T2.png\n",
      "Created test/Patient001: T1.png, T2.png\n",
      "Created test/Patient002: T1.png, T2.png\n",
      "Created test/Patient003: T1.png, T2.png\n",
      "Created test/Patient004: T1.png, T2.png\n",
      "Toy dataset created at ./data/MRI\n",
      "Directory structure:\n",
      "MRI/\n",
      "  test/\n",
      "    Patient001/\n",
      "      T1.png\n",
      "      T2.png\n",
      "      .ipynb_checkpoints/\n",
      "        T1-checkpoint.png\n",
      "        T2-checkpoint.png\n",
      "    Patient002/\n",
      "      T1.png\n",
      "      T2.png\n",
      "      .ipynb_checkpoints/\n",
      "        T1-checkpoint.png\n",
      "    Patient003/\n",
      "      T1.png\n",
      "      T2.png\n",
      "    Patient004/\n",
      "      T1.png\n",
      "      T2.png\n",
      "  train/\n",
      "    Patient001/\n",
      "      T1.png\n",
      "      T2.png\n",
      "    Patient002/\n",
      "      T1.png\n",
      "      T2.png\n",
      "    Patient003/\n",
      "      T1.png\n",
      "      T2.png\n",
      "    Patient004/\n",
      "      T1.png\n",
      "      T2.png\n",
      "  val/\n",
      "    Patient001/\n",
      "      T1.png\n",
      "      T2.png\n",
      "    Patient002/\n",
      "      T1.png\n",
      "      T2.png\n",
      "    Patient003/\n",
      "      T1.png\n",
      "      T2.png\n",
      "    Patient004/\n",
      "      T1.png\n",
      "      T2.png\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "\n",
    "def create_toy_mri_dataset(root_dir=\"./data/MRI\", image_size=(256, 256)):\n",
    "    \"\"\"\n",
    "    创建一个toy MRI数据集，包含4个患者，每个患者有T1和T2加权图像\n",
    "    \"\"\"\n",
    "    \n",
    "    splits = [\"train\", \"val\", \"test\"]\n",
    "    \n",
    "    for split in splits:\n",
    "        split_dir = os.path.join(root_dir, split)\n",
    "        os.makedirs(split_dir, exist_ok=True)\n",
    "        \n",
    "        # 为每个split创建4个患者\n",
    "        for i in range(1, 5):\n",
    "            patient_dir = os.path.join(split_dir, f\"Patient{i:03d}\")\n",
    "            os.makedirs(patient_dir, exist_ok=True)\n",
    "            \n",
    "            # 生成模拟的MRI图像\n",
    "            # T1: 通常白质亮，灰质暗，CSF暗\n",
    "            # T2: 通常白质暗，灰质亮，CSF亮\n",
    "            \n",
    "            np.random.seed(42 + i)  # 为了可重现性\n",
    "            \n",
    "            # 创建基础解剖结构\n",
    "            h, w = image_size\n",
    "            center_x, center_y = w//2, h//2\n",
    "            \n",
    "            # 创建一个简单的脑部轮廓\n",
    "            x, y = np.meshgrid(np.arange(w), np.arange(h))\n",
    "            \n",
    "            # 椭圆形脑部轮廓\n",
    "            brain_mask = ((x - center_x)**2 / (w//3)**2 + \n",
    "                         (y - center_y)**2 / (h//3)**2) < 1\n",
    "            \n",
    "            # 内部结构（简化的脑室和灰白质）\n",
    "            ventricle_mask = ((x - center_x)**2 / (w//8)**2 + \n",
    "                             (y - center_y)**2 / (h//8)**2) < 1\n",
    "            \n",
    "            # T1加权图像 (白质亮，灰质中等，脑室暗)\n",
    "            t1_image = np.zeros((h, w), dtype=np.float32)\n",
    "            t1_image[brain_mask] = 0.6 + 0.2 * np.random.randn(np.sum(brain_mask))  # 白质\n",
    "            t1_image[ventricle_mask] = 0.2 + 0.1 * np.random.randn(np.sum(ventricle_mask))  # 脑室\n",
    "            \n",
    "            # 添加一些\"灰质\"区域\n",
    "            gray_matter = brain_mask & ~ventricle_mask\n",
    "            gray_indices = np.random.choice(np.sum(gray_matter), size=np.sum(gray_matter)//3, replace=False)\n",
    "            gray_coords = np.where(gray_matter)\n",
    "            selected_coords = (gray_coords[0][gray_indices], gray_coords[1][gray_indices])\n",
    "            t1_image[selected_coords] = 0.4 + 0.1 * np.random.randn(len(gray_indices))\n",
    "            \n",
    "            # T2加权图像 (白质暗，灰质亮，脑室亮)\n",
    "            t2_image = np.zeros((h, w), dtype=np.float32)\n",
    "            t2_image[brain_mask] = 0.3 + 0.2 * np.random.randn(np.sum(brain_mask))  # 白质\n",
    "            t2_image[ventricle_mask] = 0.8 + 0.1 * np.random.randn(np.sum(ventricle_mask))  # 脑室\n",
    "            t2_image[selected_coords] = 0.7 + 0.1 * np.random.randn(len(gray_indices))  # 灰质\n",
    "            \n",
    "            # 确保值在[0,1]范围内\n",
    "            t1_image = np.clip(t1_image, 0, 1)\n",
    "            t2_image = np.clip(t2_image, 0, 1)\n",
    "            \n",
    "            # 转换为0-255的uint8并保存\n",
    "            t1_uint8 = (t1_image * 255).astype(np.uint8)\n",
    "            t2_uint8 = (t2_image * 255).astype(np.uint8)\n",
    "            \n",
    "            # 保存图像\n",
    "            Image.fromarray(t1_uint8, mode='L').save(\n",
    "                os.path.join(patient_dir, \"T1.png\")\n",
    "            )\n",
    "            Image.fromarray(t2_uint8, mode='L').save(\n",
    "                os.path.join(patient_dir, \"T2.png\")\n",
    "            )\n",
    "            \n",
    "            print(f\"Created {split}/Patient{i:03d}: T1.png, T2.png\")\n",
    "    \n",
    "    print(f\"Toy dataset created at {root_dir}\")\n",
    "    print(\"Directory structure:\")\n",
    "    for root, dirs, files in os.walk(root_dir):\n",
    "        level = root.replace(root_dir, '').count(os.sep)\n",
    "        indent = ' ' * 2 * level\n",
    "        print(f\"{indent}{os.path.basename(root)}/\")\n",
    "        subindent = ' ' * 2 * (level + 1)\n",
    "        for file in files:\n",
    "            print(f\"{subindent}{file}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    create_toy_mri_dataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f24b39ef-e09c-4168-a1d6-c17662ac0136",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_anchor shape: torch.Size([2, 1, 256, 256])\n",
      "x_pos shape: torch.Size([2, 1, 256, 256])\n"
     ]
    }
   ],
   "source": [
    "from datamodules.mri_datamodule import MRIDataModule\n",
    "\n",
    "# ====== 3. 构建小数据集 ======\n",
    "dataset = get_dataset(\n",
    "    dataset_name=\"mri_contrastive\",\n",
    "    root=\"./data/MRI\",     # 你的数据根目录\n",
    "    split=\"train\",\n",
    "    modalities=(\"T1\", \"T2\"),\n",
    "    fixed_pair=True        # 强制配对 (T1, T2)\n",
    ")\n",
    "\n",
    "# 从MRIDataModule获取静态方法\n",
    "collate_fn = MRIDataModule._collate_fn\n",
    "\n",
    "# 注意：参数名是 collate_fn，不是 _collate_fn\n",
    "loader = DataLoader(dataset, batch_size=2, shuffle=True, collate_fn=collate_fn)\n",
    "\n",
    "# 检查一下\n",
    "x_anchor, x_pos = next(iter(loader))\n",
    "print(\"x_anchor shape:\", x_anchor.shape)  # (B, 1, 256, 256)\n",
    "print(\"x_pos shape:\", x_pos.shape)        # (B, 1, 256, 256)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4327b325-1a4e-4115-b890-276c56b77558",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ====== 4. 初始化模型 ======\n",
    "model = PreTrained_AutoEncoder(\n",
    "    lr=1e-3,\n",
    "    lambda_rec=1.0,   # 先只用重建损失\n",
    "    lambda_nce=0.0,   # NCE 先关掉，避免复杂\n",
    "    proj_dim=128,\n",
    "    temperature=0.1,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "73552474-5da2-4bc6-978f-67eff554cc68",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "\n",
      "  | Name      | Type           | Params | Mode \n",
      "-----------------------------------------------------\n",
      "0 | encoder   | Shared_Encoder | 388 K  | train\n",
      "1 | decoder   | Shared_Decoder | 174 K  | train\n",
      "2 | projector | Sequential     | 49.4 K | train\n",
      "-----------------------------------------------------\n",
      "613 K     Trainable params\n",
      "0         Non-trainable params\n",
      "613 K     Total params\n",
      "2.453     Total estimated model params size (MB)\n",
      "40        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "25d910f404804b74a26bf8a72dee8c29",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: |                                                                               | 0/? [00:00<…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6624f3339f704d49b519427eafa6d372",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |                                                                                      | 0/? [00:00<…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e63931e428644872bc5d080c0e1e08a2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |                                                                                    | 0/? [00:00<…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9cde82b1ea7241a9982e4569136328cb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |                                                                                    | 0/? [00:00<…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8422096fe3ce428cb0171a31f0f665ef",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |                                                                                    | 0/? [00:00<…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=3` reached.\n"
     ]
    }
   ],
   "source": [
    "from pytorch_lightning.callbacks import TQDMProgressBar\n",
    "# ====== 4. Trainer 训练 ======\n",
    "trainer = pl.Trainer(\n",
    "    max_epochs=3,        # 小规模调试\n",
    "    accelerator=\"cpu\",   # 本地 CPU 就好\n",
    "    devices=1,\n",
    "    log_every_n_steps=1\n",
    ")\n",
    "\n",
    "trainer.fit(model, loader, loader)  # train/val 都用同一个 loader 先跑通"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4d3575f8-3115-4e97-a0ae-20f83fae1ac9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input: torch.Size([1, 1, 256, 256]) -> Recon: torch.Size([1, 1, 256, 256])\n"
     ]
    }
   ],
   "source": [
    "# ====== 5. Debug 验证输出 ======\n",
    "# 随便取一条数据跑 forward\n",
    "x_anchor, x_pos = dataset[0]\n",
    "x_anchor = x_anchor.unsqueeze(0)  # (1,1,256,256)\n",
    "with torch.no_grad():\n",
    "    recon = model(x_anchor)\n",
    "print(\"Input:\", x_anchor.shape, \"-> Recon:\", recon.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a395a821-a547-4841-9663-5c3ef4b1e870",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
