{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "73944974-5740-4bc8-bdc8-8ad3c991a1b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "v_pred shape: torch.Size([2, 256, 16, 16])\n",
      "Loss: 1.1204676628112793\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# ====== ä¸€ä¸ªç®€å•çš„ Shared Encoder ï¼ˆtoy ç‰ˆæœ¬ï¼Œéšä¾¿å·ç§¯ä¸€ä¸‹ï¼‰ ======\n",
    "class SharedEncoder(nn.Module):\n",
    "    def __init__(self, in_ch=1, out_ch=256):\n",
    "        super().__init__()\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Conv2d(in_ch, 32, 3, padding=1, stride=2),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(32, 64, 3, padding=1, stride=2),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(64, out_ch, 3, padding=1, stride=2),\n",
    "            nn.ReLU(),\n",
    "        )\n",
    "    def forward(self, x):\n",
    "        return self.encoder(x)  # (B, out_ch, H/8, W/8)\n",
    "\n",
    "# ====== å¯¼å…¥ä½ å†™çš„ UNetFlow ======\n",
    "from flow_matching_unet import UNetFlow\n",
    "\n",
    "# ====== Flow Matching æ¡†æ¶æœ€å°ç¤ºä¾‹ ======\n",
    "class FlowMatchingWrapper(nn.Module):\n",
    "    def __init__(self, in_channels=256, cond_dim=256):\n",
    "        super().__init__()\n",
    "        self.unet = UNetFlow(\n",
    "            in_channels=in_channels,\n",
    "            base_channels=64,\n",
    "            time_emb_dim=128,\n",
    "            depth=4,\n",
    "            use_cross_attn=True,\n",
    "            cond_dim=cond_dim\n",
    "        )\n",
    "\n",
    "    def forward(self, x_t, cond_feats, t, cond_mask=None):\n",
    "        # v_pred: (B, C, H, W)\n",
    "        return self.unet(x_t, cond_feats, t, cond_mask)\n",
    "\n",
    "\n",
    "# ====== æµ‹è¯• pipeline ======\n",
    "if __name__ == \"__main__\":\n",
    "    B, C, H, W = 2, 1, 128, 128   # ä¸¤ä¸ªæ ·æœ¬ï¼Œå•é€šé“ MRI slice\n",
    "    N, C_cond = 3, 256           # æ¡ä»¶æ¨¡æ€æ•° 3 (T1/T2/FLAIR)ï¼Œembedding dim = 256\n",
    "\n",
    "    # è¾“å…¥åŸå§‹ MRI å›¾åƒ\n",
    "    img = torch.randn(B, C, H, W)  # toy MRI slice\n",
    "    encoder = SharedEncoder(in_ch=1, out_ch=256)\n",
    "    x_0 = encoder(img)             # (B, 256, H/8, W/8)\n",
    "\n",
    "    # æ„é€  flow matching è¾“å…¥\n",
    "    t = torch.randint(0, 1000, (B,))          # æ—¶é—´æ­¥\n",
    "    noise = torch.randn_like(x_0)\n",
    "    x_t = x_0 + noise * 0.1                   # åŠ å™ªå£°çš„ latent\n",
    "\n",
    "    cond_feats = torch.randn(B, N, C_cond)    # æ¡ä»¶æ¨¡æ€ embedding\n",
    "    cond_mask = torch.tensor([[1,1,1],[1,0,1]])  # ç¬¬äºŒä¸ªæ ·æœ¬ç¼ºä¸€ä¸ªæ¨¡æ€\n",
    "\n",
    "    # è°ƒç”¨æ¨¡å‹\n",
    "    model = FlowMatchingWrapper(in_channels=256, cond_dim=C_cond)\n",
    "    v_pred = model(x_t, cond_feats, t, cond_mask)  # (B, 256, H/8, W/8)\n",
    "\n",
    "    # æ„é€  target å‘é‡åœºï¼ˆè¿™é‡Œåªæ˜¯ toyï¼‰\n",
    "    v_target = noise\n",
    "\n",
    "    # æŸå¤±\n",
    "    loss = F.mse_loss(v_pred, v_target)\n",
    "    print(\"v_pred shape:\", v_pred.shape)\n",
    "    print(\"Loss:\", loss.item())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dfb9c1b-d69b-4c47-9fc6-13cae86ba19b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "æœ¬åœ°CPUæµ‹è¯•Demo - FusionTransformer + FlowMatchingUNet\n",
    "æµ‹è¯•ä¸¤ä¸ªæ¨¡å—çš„é›†æˆå’ŒåŠŸèƒ½\n",
    "\"\"\"\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "from typing import Optional, Dict, Any\n",
    "import time\n",
    "import os\n",
    "import sys\n",
    "\n",
    "# æ£€æŸ¥æ–‡ä»¶æ˜¯å¦å­˜åœ¨\n",
    "required_files = ['fusion_transformer.py', 'flow_matching_unet.py']\n",
    "for file in required_files:\n",
    "    if not os.path.exists(file):\n",
    "        raise FileNotFoundError(f\"Required file '{file}' not found in current directory!\")\n",
    "\n",
    "# å¯¼å…¥è‡ªå®šä¹‰æ¨¡å—\n",
    "try:\n",
    "    from fusion_transformer import FusionTransformer\n",
    "    from flow_matching_unet import UNetFlow\n",
    "    print(\"âœ… Successfully imported FusionTransformer and UNetFlow\")\n",
    "except ImportError as e:\n",
    "    print(f\"âŒ Import error: {e}\")\n",
    "    sys.exit(1)\n",
    "\n",
    "class MRIFlowMatchingDemo:\n",
    "    \"\"\"MRI Flow Matching å®Œæ•´æµ‹è¯•Demo\"\"\"\n",
    "    \n",
    "    def __init__(self, device='cpu'):\n",
    "        self.device = torch.device(device)\n",
    "        self.setup_test_config()\n",
    "        self.create_models()\n",
    "        \n",
    "    def setup_test_config(self):\n",
    "        \"\"\"è®¾ç½®æµ‹è¯•é…ç½®\"\"\"\n",
    "        # æ¨¡æ‹ŸMRIæ•°æ®é…ç½®\n",
    "        self.batch_size = 2\n",
    "        self.img_height, self.img_width = 64, 64  # å°å°ºå¯¸ä¾¿äºCPUæµ‹è¯•\n",
    "        self.in_channels = 256  # encoderè¾“å‡ºé€šé“æ•°\n",
    "        self.n_modalities = 4   # T1, T2, FLAIR, DWI\n",
    "        \n",
    "        # FusionTransformeré…ç½®\n",
    "        self.C_tok = 256        # tokenç‰¹å¾ç»´åº¦\n",
    "        self.C_cond = 128       # æ¡ä»¶ç‰¹å¾ç»´åº¦\n",
    "        \n",
    "        # UNetFlowé…ç½®\n",
    "        self.base_channels = 64\n",
    "        self.time_emb_dim = 128\n",
    "        self.depth = 3          # UNetæ·±åº¦ï¼ŒCPUå‹å¥½\n",
    "        \n",
    "        # é€‰æ‹©å™¨é…ç½®\n",
    "        self.selector_config = {\n",
    "            \"mode\": \"auto\",\n",
    "            \"ratio_shallow\": 0.6,\n",
    "            \"ratio_deep\": 0.3,\n",
    "            \"temp\": 1.0\n",
    "        }\n",
    "        \n",
    "    def create_models(self):\n",
    "        \"\"\"åˆ›å»ºæ¨¡å‹å®ä¾‹\"\"\"\n",
    "        print(\"\\nğŸ”§ Creating models...\")\n",
    "        \n",
    "        # åˆ›å»ºFusionTransformer\n",
    "        self.fusion_transformer = FusionTransformer(\n",
    "            C_tok=self.C_tok,\n",
    "            C_cond=self.C_cond,\n",
    "            n_heads=4,\n",
    "            n_layers=2,\n",
    "            dropout=0.05,\n",
    "            max_N=8\n",
    "        ).to(self.device)\n",
    "        \n",
    "        # åˆ›å»ºUNetFlow\n",
    "        self.unet_flow = UNetFlow(\n",
    "            in_channels=self.in_channels,\n",
    "            base_channels=self.base_channels,\n",
    "            time_emb_dim=self.time_emb_dim,\n",
    "            depth=self.depth,\n",
    "            use_cross_attn=True,\n",
    "            cond_dim=self.C_cond,\n",
    "            kv_dim=None,  # é»˜è®¤ä¸dimç›¸åŒ\n",
    "            selector_config=self.selector_config\n",
    "        ).to(self.device)\n",
    "        \n",
    "        print(f\"âœ… Models created on device: {self.device}\")\n",
    "        self.print_model_info()\n",
    "        \n",
    "    def print_model_info(self):\n",
    "        \"\"\"æ‰“å°æ¨¡å‹ä¿¡æ¯\"\"\"\n",
    "        fusion_params = sum(p.numel() for p in self.fusion_transformer.parameters())\n",
    "        unet_params = sum(p.numel() for p in self.unet_flow.parameters())\n",
    "        \n",
    "        print(f\"ğŸ“Š FusionTransformer parameters: {fusion_params:,}\")\n",
    "        print(f\"ğŸ“Š UNetFlow parameters: {unet_params:,}\")\n",
    "        print(f\"ğŸ“Š Total parameters: {fusion_params + unet_params:,}\")\n",
    "        \n",
    "    def generate_test_data(self):\n",
    "        \"\"\"ç”Ÿæˆæµ‹è¯•æ•°æ®\"\"\"\n",
    "        print(\"\\nğŸ“ Generating test data...\")\n",
    "        \n",
    "        # æ¨¡æ‹Ÿæ¥è‡ªshared encoderçš„tokenç‰¹å¾\n",
    "        # æ¯ä¸ªæ¨¡æ€å‹ç¼©æˆä¸€ä¸ªtokenå‘é‡\n",
    "        tokens = torch.randn(\n",
    "            self.batch_size, \n",
    "            self.n_modalities, \n",
    "            self.C_tok, \n",
    "            device=self.device\n",
    "        )\n",
    "        \n",
    "        # æ¡ä»¶æ©ç ï¼šæ¨¡æ‹ŸæŸäº›æ¨¡æ€ç¼ºå¤±çš„æƒ…å†µ\n",
    "        cond_mask = torch.ones(self.batch_size, self.n_modalities, device=self.device)\n",
    "        # æ¨¡æ‹Ÿç¬¬ä¸€ä¸ªæ ·æœ¬ç¼ºå¤±æœ€åä¸€ä¸ªæ¨¡æ€\n",
    "        cond_mask[0, -1] = 0\n",
    "        \n",
    "        # æ¨¡æ‹Ÿè¾“å…¥ç‰¹å¾å›¾ (æ¥è‡ªshared encoder)\n",
    "        x_t = torch.randn(\n",
    "            self.batch_size, \n",
    "            self.in_channels, \n",
    "            self.img_height, \n",
    "            self.img_width,\n",
    "            device=self.device\n",
    "        )\n",
    "        \n",
    "        # æ—¶é—´æ­¥\n",
    "        t = torch.rand(self.batch_size, device=self.device) * 1000\n",
    "        \n",
    "        return {\n",
    "            'tokens': tokens,\n",
    "            'cond_mask': cond_mask,\n",
    "            'x_t': x_t,\n",
    "            't': t\n",
    "        }\n",
    "        \n",
    "    def test_fusion_transformer(self, test_data):\n",
    "        \"\"\"æµ‹è¯•FusionTransformer\"\"\"\n",
    "        print(\"\\nğŸ§ª Testing FusionTransformer...\")\n",
    "        \n",
    "        tokens = test_data['tokens']\n",
    "        cond_mask = test_data['cond_mask']\n",
    "        \n",
    "        print(f\"Input tokens shape: {tokens.shape}\")\n",
    "        print(f\"Input cond_mask shape: {cond_mask.shape}\")\n",
    "        print(f\"Cond_mask content:\\n{cond_mask}\")\n",
    "        \n",
    "        # å‰å‘ä¼ æ’­\n",
    "        start_time = time.time()\n",
    "        with torch.no_grad():\n",
    "            cond_feats = self.fusion_transformer(tokens, cond_mask)\n",
    "        end_time = time.time()\n",
    "        \n",
    "        if cond_feats is not None:\n",
    "            print(f\"âœ… Output cond_feats shape: {cond_feats.shape}\")\n",
    "            print(f\"â±ï¸  Forward time: {end_time - start_time:.4f}s\")\n",
    "            print(f\"ğŸ“Š Output stats - Mean: {cond_feats.mean().item():.4f}, Std: {cond_feats.std().item():.4f}\")\n",
    "            \n",
    "            # éªŒè¯è¾“å‡ºç»´åº¦\n",
    "            expected_shape = (self.batch_size, self.n_modalities, self.C_cond)\n",
    "            assert cond_feats.shape == expected_shape, f\"Shape mismatch: {cond_feats.shape} != {expected_shape}\"\n",
    "            print(\"âœ… Shape validation passed\")\n",
    "        else:\n",
    "            print(\"âŒ FusionTransformer returned None (disabled)\")\n",
    "            \n",
    "        return cond_feats\n",
    "        \n",
    "    def test_unet_flow(self, test_data, cond_feats):\n",
    "        \"\"\"æµ‹è¯•UNetFlow\"\"\"\n",
    "        print(\"\\nğŸ§ª Testing UNetFlow...\")\n",
    "        \n",
    "        x_t = test_data['x_t']\n",
    "        t = test_data['t']\n",
    "        cond_mask = test_data['cond_mask']\n",
    "        \n",
    "        print(f\"Input x_t shape: {x_t.shape}\")\n",
    "        print(f\"Input t shape: {t.shape}\")\n",
    "        print(f\"Input cond_feats shape: {cond_feats.shape if cond_feats is not None else None}\")\n",
    "        \n",
    "        # å‰å‘ä¼ æ’­\n",
    "        start_time = time.time()\n",
    "        with torch.no_grad():\n",
    "            velocity = self.unet_flow(x_t, cond_feats, t, cond_mask)\n",
    "        end_time = time.time()\n",
    "        \n",
    "        print(f\"âœ… Output velocity shape: {velocity.shape}\")\n",
    "        print(f\"â±ï¸  Forward time: {end_time - start_time:.4f}s\")\n",
    "        print(f\"ğŸ“Š Output stats - Mean: {velocity.mean().item():.4f}, Std: {velocity.std().item():.4f}\")\n",
    "        \n",
    "        # éªŒè¯è¾“å‡ºç»´åº¦\n",
    "        assert velocity.shape == x_t.shape, f\"Shape mismatch: {velocity.shape} != {x_t.shape}\"\n",
    "        print(\"âœ… Shape validation passed\")\n",
    "        \n",
    "        return velocity\n",
    "        \n",
    "    def test_different_selector_modes(self, test_data, cond_feats):\n",
    "        \"\"\"æµ‹è¯•ä¸åŒçš„é€‰æ‹©å™¨æ¨¡å¼\"\"\"\n",
    "        print(\"\\nğŸ§ª Testing different selector modes...\")\n",
    "        \n",
    "        modes = [\"all\", \"auto\", \"topk_q\", \"topk_central\", \"weighted\"]\n",
    "        \n",
    "        for mode in modes:\n",
    "            print(f\"\\n--- Testing selector mode: {mode} ---\")\n",
    "            \n",
    "            # æ›´æ–°é€‰æ‹©å™¨é…ç½®\n",
    "            selector_config = {\"mode\": mode, \"k\": 2, \"temp\": 1.0}\n",
    "            self.unet_flow.set_selector_config(selector_config)\n",
    "            \n",
    "            try:\n",
    "                start_time = time.time()\n",
    "                with torch.no_grad():\n",
    "                    velocity = self.unet_flow(\n",
    "                        test_data['x_t'], \n",
    "                        cond_feats, \n",
    "                        test_data['t'], \n",
    "                        test_data['cond_mask']\n",
    "                    )\n",
    "                end_time = time.time()\n",
    "                \n",
    "                print(f\"âœ… Mode {mode}: Success, time: {end_time - start_time:.4f}s\")\n",
    "                print(f\"   Output stats - Mean: {velocity.mean().item():.4f}, Std: {velocity.std().item():.4f}\")\n",
    "                \n",
    "            except Exception as e:\n",
    "                print(f\"âŒ Mode {mode}: Failed with error: {e}\")\n",
    "                \n",
    "    def test_missing_modalities(self):\n",
    "        \"\"\"æµ‹è¯•ç¼ºå¤±æ¨¡æ€çš„æƒ…å†µ\"\"\"\n",
    "        print(\"\\nğŸ§ª Testing missing modalities scenarios...\")\n",
    "        \n",
    "        scenarios = [\n",
    "            (\"All modalities\", torch.ones(self.batch_size, self.n_modalities)),\n",
    "            (\"Missing last modality\", torch.tensor([[1,1,1,0], [1,1,1,1]])),\n",
    "            (\"Missing multiple\", torch.tensor([[1,0,1,0], [1,1,0,1]])),\n",
    "            (\"Only one modality\", torch.tensor([[1,0,0,0], [0,1,0,0]]))\n",
    "        ]\n",
    "        \n",
    "        for scenario_name, mask in scenarios:\n",
    "            print(f\"\\n--- {scenario_name} ---\")\n",
    "            print(f\"Mask: {mask}\")\n",
    "            \n",
    "            # ç”Ÿæˆå¯¹åº”çš„æµ‹è¯•æ•°æ®\n",
    "            tokens = torch.randn(self.batch_size, self.n_modalities, self.C_tok, device=self.device)\n",
    "            x_t = torch.randn(self.batch_size, self.in_channels, self.img_height, self.img_width, device=self.device)\n",
    "            t = torch.rand(self.batch_size, device=self.device) * 1000\n",
    "            cond_mask = mask.to(self.device)\n",
    "            \n",
    "            try:\n",
    "                with torch.no_grad():\n",
    "                    cond_feats = self.fusion_transformer(tokens, cond_mask)\n",
    "                    velocity = self.unet_flow(x_t, cond_feats, t, cond_mask)\n",
    "                \n",
    "                print(f\"âœ… {scenario_name}: Success\")\n",
    "                print(f\"   Velocity stats - Mean: {velocity.mean().item():.4f}, Std: {velocity.std().item():.4f}\")\n",
    "                \n",
    "            except Exception as e:\n",
    "                print(f\"âŒ {scenario_name}: Failed with error: {e}\")\n",
    "                \n",
    "    def test_gradient_flow(self):\n",
    "        \"\"\"æµ‹è¯•æ¢¯åº¦æµ\"\"\"\n",
    "        print(\"\\nğŸ§ª Testing gradient flow...\")\n",
    "        \n",
    "        # å¯ç”¨æ¢¯åº¦è®¡ç®—\n",
    "        self.fusion_transformer.train()\n",
    "        self.unet_flow.train()\n",
    "        \n",
    "        # ç”Ÿæˆæµ‹è¯•æ•°æ®\n",
    "        test_data = self.generate_test_data()\n",
    "        \n",
    "        # éœ€è¦æ¢¯åº¦çš„è¾“å…¥\n",
    "        tokens = test_data['tokens'].requires_grad_(True)\n",
    "        x_t = test_data['x_t'].requires_grad_(True)\n",
    "        \n",
    "        # å‰å‘ä¼ æ’­\n",
    "        cond_feats = self.fusion_transformer(tokens, test_data['cond_mask'])\n",
    "        velocity = self.unet_flow(x_t, cond_feats, test_data['t'], test_data['cond_mask'])\n",
    "        \n",
    "        # è®¡ç®—æŸå¤±å¹¶åå‘ä¼ æ’­\n",
    "        loss = velocity.mean()\n",
    "        loss.backward()\n",
    "        \n",
    "        # æ£€æŸ¥æ¢¯åº¦\n",
    "        fusion_grads = [p.grad for p in self.fusion_transformer.parameters() if p.grad is not None]\n",
    "        unet_grads = [p.grad for p in self.unet_flow.parameters() if p.grad is not None]\n",
    "        \n",
    "        print(f\"âœ… FusionTransformer gradients: {len(fusion_grads)} parameters have gradients\")\n",
    "        print(f\"âœ… UNetFlow gradients: {len(unet_grads)} parameters have gradients\")\n",
    "        \n",
    "        if fusion_grads:\n",
    "            fusion_grad_norm = torch.sqrt(sum(torch.sum(g**2) for g in fusion_grads))\n",
    "            print(f\"ğŸ“Š FusionTransformer gradient norm: {fusion_grad_norm.item():.6f}\")\n",
    "            \n",
    "        if unet_grads:\n",
    "            unet_grad_norm = torch.sqrt(sum(torch.sum(g**2) for g in unet_grads))\n",
    "            print(f\"ğŸ“Š UNetFlow gradient norm: {unet_grad_norm.item():.6f}\")\n",
    "            \n",
    "        # æ¢å¤evalæ¨¡å¼\n",
    "        self.fusion_transformer.eval()\n",
    "        self.unet_flow.eval()\n",
    "        \n",
    "    def run_all_tests(self):\n",
    "        \"\"\"è¿è¡Œæ‰€æœ‰æµ‹è¯•\"\"\"\n",
    "        print(\"ğŸš€ Starting comprehensive tests...\")\n",
    "        print(f\"Device: {self.device}\")\n",
    "        print(f\"PyTorch version: {torch.__version__}\")\n",
    "        \n",
    "        try:\n",
    "            # 1. åŸºç¡€åŠŸèƒ½æµ‹è¯•\n",
    "            test_data = self.generate_test_data()\n",
    "            cond_feats = self.test_fusion_transformer(test_data)\n",
    "            velocity = self.test_unet_flow(test_data, cond_feats)\n",
    "            \n",
    "            # 2. é€‰æ‹©å™¨æ¨¡å¼æµ‹è¯•\n",
    "            self.test_different_selector_modes(test_data, cond_feats)\n",
    "            \n",
    "            # 3. ç¼ºå¤±æ¨¡æ€æµ‹è¯•\n",
    "            self.test_missing_modalities()\n",
    "            \n",
    "            # 4. æ¢¯åº¦æµæµ‹è¯•\n",
    "            self.test_gradient_flow()\n",
    "            \n",
    "            print(\"\\nğŸ‰ All tests completed successfully!\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"\\nâŒ Test failed with error: {e}\")\n",
    "            import traceback\n",
    "            traceback.print_exc()\n",
    "\n",
    "def main():\n",
    "    \"\"\"ä¸»å‡½æ•°\"\"\"\n",
    "    print(\"=\" * 60)\n",
    "    print(\"MRI Flow Matching - Local CPU Demo\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    # è®¾ç½®éšæœºç§å­\n",
    "    torch.manual_seed(42)\n",
    "    np.random.seed(42)\n",
    "    \n",
    "    # åˆ›å»ºå¹¶è¿è¡Œæµ‹è¯•\n",
    "    demo = MRIFlowMatchingDemo(device='cpu')\n",
    "    demo.run_all_tests()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4a4e549-a625-4567-8266-f0755f65b2c4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
